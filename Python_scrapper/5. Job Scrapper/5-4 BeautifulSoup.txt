우리가 get 함수와 text 함수를 이용하여 얻어온 웹사이트의 HTML은 매우 복잡하고 여기에서 무언가를 바로 얻어내기가 쉽지 않다.

1. 우선 우리가 해야 할 것은 jobs라는 class를 가진 section을 찾는 것이다. 그리고 나서 section 안에 있는 ul에 속하는 모든 li들을 찾아낼
것이다.
- Beautiful Soup: HTML 코드(텍스ㅌ,) 안의 내용을 검색하기 위해 사용 가능한 파이썬 패키지이다. beautifulsoup는 아주 좋은 method들을 제공한다.
* 공식 문서를 참조하면 도움이 많이 된다.

- find_all 메소드: 우리가 가진 document에서 HTML 태그를 찾을 수 있게 해 준다.
ex) soup.find_all("title")     --> 결과: [<title>The Dormouse's story</title>]
ex) soup.find_all("p", "title")     --> 결과: [<p class="title"><b>The Dormouse's story</b></p>]
ex) soup.find_all("a")     --> 결과: [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, 
<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
ex) soup.find_all(id="link2")     --> 결과: [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]


2. beautifulsoup import 하기
from bs4 import BeautifulSoup     --> bs4 모듈로부터 BeautifulSoup 함수 import
soup = BeautifulSoup(html_doc, 'html.parser')     --> BeautifulSoup 함수를 호출해 주고 html을 첫번째 argument로 전해주고 'html.parser'라는 문자열을 전해줄 것임.
내가 작성한 코드에서 html_doc는 response.text와 같기 때문에 이를 이용하여 조건문을 수정해주면 된다.

* "html.parser"는 html_doc에 해당하는 문자열은 단순한 text가 아닌 HTML 구조에 맞게 작성되어 있으므로 함수에게도 HTML의 관점으로
   html_doc에 해당하는 문자열을 이해해 달라고 요청하는 것과 같은 코드이다.

if response.status_code != 200:
  print("Can't request website")
else:     --> 검색어를 입력한 주소에 해당하는 웹사이트에 get 요청을 보냈을 시 상태 코드가 200이라면(응답을 성공적으로 얻어왔다면)
  soup = BeautifulSoup(response.text, "html.parser")     --> BeautifulSoup 함수 사용 (첫 번째 인자로 해당 주소의 HTML text 넣어주고, 
  print(soup.find_all("title"))     --> 가져온 HTML text에서 "title"이 있는 tag들을 모두 찾아 리스트에 담아서 돌려줌. 

결과로 <title>We Work Remotely: Advanced Remote Job Search</title>이 나오는 것을 확인 가능하다.

* 만약 찾지 못하면 빈 리스트가 결과로 나오게 된다.


3. 이제 우리가 원하는 것을 찾기 위한 과정에 속하는 jobs라는 class를 가진 section을 찾아볼 것이다.
print(soup.find_all("section", class_="jobs"))     --> 다음과 같이 수정해주면 된다. 주의할 점은 class를 적을 때 _와 같이 적어주어야 
                                                                    한다는 것이다.
결과로 역시 긴 코드들이 나왔고 제대로 작동한 것을 확인할 수 있었다.

